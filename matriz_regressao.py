# -*- coding: utf-8 -*-
"""matriz_confusao e regressao_logistica

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WZ2wEou_ZOY1-L8ch21EDxCDZX35qlnN
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/tabela_final_tratada.csv')

df

df.describe()

df.info()

# Média, mediana, desvio padrão, máximos e mínimos

df = pd.read_csv('/content/tabela_final_tratada.csv')

summary = numeric_df.agg(['mean', 'median', 'std', 'min', 'max'])

summary = summary.round(2)

print(summary)

"""**Matriz de correlação**: há uma alta correlação entre as variáveis number_times_delayed_payment_loan_30_59_days, number_times_delayed_payment_loan_60_89_days e more_90_days_overdue. Como a variável more_90_days_overdue está envolvida nas hipóteses iniciais e por se tratar da maior taxa de atraso entre todas as variáveis, esta foi escolhida para o cálculo do score e no modelo de regressão."""

# Matriz de correlação
correlation_matrix = numerical_df.corr()

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de correlação')
plt.show()

#Histograma e boxplot de idade

plt.figure(figsize=(12, 4))
plt.hist(df['age'], bins=25, color='white', edgecolor='black')
plt.title('Histograma de idade', fontsize=14)
plt.xlabel('Age', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.show()

plt.figure(figsize=(12,2))
sns.boxplot(x='age', data=df, orient='v')
plt.title('Boxplot idade', fontsize=14)
plt.xlabel('Age', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.show()

#Boxplot de more_90_days_overdue

df = pd.read_csv('/content/tabela_final_tratada.csv')

plt.figure(figsize=(8, 4))
sns.boxplot(x='more_90_days_overdue', data=df, orient='v')
plt.title('Boxplot > 90 dias atraso')
plt.xlabel('more_90_days_overdue', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.show()

#Histograma e boxplot de salário

plt.figure(figsize=(12, 4))
plt.hist(df['last_month_salary_limpo'], bins=25, color='white', edgecolor='black')
plt.title('Histograma de salário', fontsize=14)
plt.xlabel('Salário', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.show()

plt.figure(figsize=(8, 4))
sns.boxplot(x='last_month_salary_limpo', data=df, orient='v')
plt.title('Boxplot salário')
plt.xlabel('last month salary', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.show()

# Boxplot de salários em relação a adimplentes e inadimplentes (limitado até $ 40000)


adimplentes = df[(df['default_flag'] == 0) & (df['last_month_salary_limpo'] < 40000)]['last_month_salary_limpo']
inadimplentes = df[(df['default_flag'] == 1) & (df['last_month_salary_limpo'] < 40000)]['last_month_salary_limpo']

plt.figure(figsize=(8, 6))
# Pass dictionaries with styling options to boxprops and medianprops
plt.boxplot([adimplentes, inadimplentes], patch_artist=True, medianprops={'color': 'black'})
plt.xticks([1, 2], ['adimplentes', 'inadimplentes'])
plt.ylabel('salário')
plt.title('Boxplot salário x adimplência')

"""**Matriz de Confusão (Marco 2)**"""

#Criação da Matriz de confusão

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('/content/score.csv')

# Valores reais e preditivos
y_true = df['default_flag']
y_pred = df['score_0_1']

# Cálculo da matriz de confusão
cm = confusion_matrix(y_true, y_pred)

# Métricas de avaliação
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

# Exibir matriz de confusão
conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto: Negativo', 'Previsto: Positivo'], yticklabels=['Real: Negativo', 'Real: Positivo'])
plt.title('Matriz de Confusão')
plt.show()

# Exibir matriz de confusão
print("\033[1mMatriz de Confusão:\033[0m")
print(cm)

# Métricas de Avaliação do Modelo
print("\n\033[1mMétricas de Avaliação:\033[0m")
print(f"Exatidão (Accuracy): {accuracy: .3f}")
print(f"Precisão: {precision: .3f}")
print(f"Sensibilidade (Recall): {recall: .3f}")
print(f"F1-score: {f1: .3f}")

# Precision, Recall e F1-Score: Especialmente úteis para classes minoritárias.

"""**Aplicando Oversampling**"""

# Aplicando oversampling (aumentando o número de exemplos de maus pagadores (classe 1) no conjunto de treinamento)
# O SMOTE (Synthetic Minority Over-sampling Technique) gera exemplos sintéticos interpolando entre exemplos da classe minoritária.

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler

# Carregar os dados
df = pd.read_csv('/content/score.csv')

# Separar as características (X) e a variável dependente (y)
X = df[['age_dummy', 'dependent_dummy', 'salary_dummy', 'total_loans_dummy', 'more_90_days_dummy', 'using_lines_dummy', 'debt_ratio_dummy']]
y = df['default_flag']

# Dividir os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Estandarizar as características (opcional, dependendo do modelo)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Aplicar SMOTE aos dados de treinamento
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Criar o modelo de RandomForestClassifier
model = RandomForestClassifier(random_state=42)

# Treinar o modelo com os dados resampleados
model.fit(X_train_resampled, y_train_resampled)

# Realizar predições no conjunto de teste
y_pred = model.predict(X_test)

# Métricas de avaliação
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Cálculo da matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)

# Exibir matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto: Negativo', 'Previsto: Positivo'], yticklabels=['Real: Negativo', 'Real: Positivo'])
plt.title('Matriz de Confusão')
plt.show()

# Exibir matriz de confusão
print("\033[1mMatriz de Confusão:\033[0m")
print(conf_matrix)

# Métricas de Avaliação do Modelo
print("\n\033[1mMétricas de Avaliação:\033[0m")
print(f"Exatidão (Accuracy): {accuracy: .3f}")
print(f"Precisão: {precision: .3f}")
print(f"Sensibilidade (Recall): {recall:.3f}")
print(f"F1-score: {f1:.3f}")

"""**Aplicando Undersampling**"""

# Aplicando Under-Sampling para balancear os dados (reduzindo aleatoriamente exemplos de bons pagadores).
# Vantagem: Reduz o tempo de treinamento.
# Desvantagem: Pode perder informação importante.

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from imblearn.under_sampling import RandomUnderSampler
from sklearn.preprocessing import StandardScaler

# Carregar os dados
df = pd.read_csv('/content/score.csv')

# Preparar os dados para o modelo
X = df[['age_dummy', 'dependent_dummy', 'salary_dummy', 'total_loans_dummy', 'more_90_days_dummy', 'using_lines_dummy', 'debt_ratio_dummy']]
y = df['default_flag']

# Dividir os dados em conjunto de treino e teste (70% treino e 30% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

# Estandarizar as características (opcional, dependendo do modelo)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Aplicar undersampling aos dados de treinamento
undersampler = RandomUnderSampler(random_state=42)
X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)

# Criar o modelo de RandomForestClassifier
model = RandomForestClassifier(random_state=42)

# Treinar o modelo com os dados resampleados
model.fit(X_train_resampled, y_train_resampled)

# Realizar predições no conjunto de teste
y_pred = model.predict(X_test)

# Métricas de avaliação do modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Exibir matriz de confusão dos dados
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto: Negativo', 'Previsto: Positivo'], yticklabels=['Real: Negativo', 'Real: Positivo'])
plt.title('Matriz de Confusão')
plt.show()

# Métricas de Avaliação do Modelo
print("\033[1mMétricas de Avaliação:\033[0m")
print(f"Exatidão (Accuracy): {accuracy: .3f}")
print(f"Precisão: {precision: .3f}")
print(f"Sensibilidade (Recall): {recall: .3f}")
print(f"F1-score: {f1: .3f}")

"""**Avaliar variáveis**"""

# Obter o ranking das características
ranking = selector.ranking_
features = X.columns

# Criar um DataFrame com os rankings
ranking_df = pd.DataFrame({'Feature': features, 'Ranking': ranking})
ranking_df = ranking_df.sort_values(by='Ranking')

# Plotar o gráfico de barras com o ranking das características
plt.figure(figsize=(10, 6))
sns.barplot(x='Ranking', y='Feature', data=ranking_df, palette='viridis')
plt.title('Ranking das variáveis')
plt.xlabel('Ranking')
plt.ylabel('variáveis dummy')
plt.show()

"""more_90_days_dummy: Esta variável é a mais representativa para prever default_flag. Portanto, essa variável deve ter um impacto significativo na probabilidade de default.

using_lines_dummy e debt_ratio_dummy: Estas características são também importantes, mas menos do que more_90_days_dummy, mas elas ainda podem ser consideradas importantes para a construção de um modelo mais robusto.

Outras Características: As variáveis age_dummy, dependent_dummy, salary_dummy, e total_loans_dummy são consideradas menos importantes pelo RFE. Elas têm classificações mais altas, sugerindo que seu impacto na previsão do default é menor comparado às características selecionadas.

**Regressão Logística**
"""

# Regressão logística com RFE e Class Weight
# O objetivo da RFE é selecionar um subconjunto de características que melhor contribuem para a predição do modelo, eliminando iterativamente as características menos importantes.
# Class_weight ajusta os pesos associados a cada classe para equilibrar essa diferença de frequências.

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, log_loss, roc_curve
from sklearn.feature_selection import RFE

# Carregar os dados
df = pd.read_csv('/content/score.csv')

# Separar as características (X) e a variável dependente (y)
X = df[['age_dummy', 'dependent_dummy', 'salary_dummy', 'total_loans_dummy', 'more_90_days_dummy', 'using_lines_dummy', 'debt_ratio_dummy']]
y = df['default_flag']

# Dividir os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Estandarizar as características
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar o modelo de regressão logística
model = LogisticRegression(class_weight='balanced')

# Aplicar Recursive Feature Elimination (RFE) para melhorar a performance do modelo, identificando e utilizando as características mais relevantes.
selector = RFE(model, n_features_to_select=1)
selector = selector.fit(X_train, y_train)

# Treinar o modelo
model.fit(X_train, y_train)

# Realizar predições no conjunto de teste
y_pred = model.predict(X_test)

# Avaliar o modelo
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Calcular métricas de avaliação
tn, fp, fn, tp = conf_matrix.ravel()
precision = tp / (tp + fp)
sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)

# Calcular AUC-ROC e Log-Loss
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
log_loss_value = log_loss(y_test, model.predict_proba(X_test))

# Calcular a curva ROC
fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])

# Calcular e exibir a matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Previsto: Negativo', 'Previsto: Positivo'], yticklabels=['Real: Negativo', 'Real: Positivo'])
plt.title('Matriz de Confusão')
plt.show()

# Visualização da curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC-ROC = {roc_auc:.3f}')
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (False Positive Rate)')
plt.ylabel('Taxa de Verdadeiros Positivos (True Positive Rate)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

# Imprimir resultados
print("\033[1mRegressão Logística:\033[0m")
print(conf_matrix)

print("\n\033[1mMétricas de Avaliação:\033[0m")
print(f"Exatidão (Accuracy): {accuracy: .3f}")
print(f"Precisão: {precision: .3f}")
print(f"Sensibilidade (Recall): {sensitivity: .3f}")
print(f"F1-score: {f1_score: .3f}")
print(f"AUC-ROC: {roc_auc: .3f}")
print(f"Log-Loss: {log_loss_value: .3f}")

# Avaliar o modelo nos dados de treino
train_accuracy = accuracy_score(y_train, model.predict(X_train))

# Avaliar o modelo nos dados de teste
test_accuracy = accuracy_score(y_test, y_pred)

print(f'Acurácia no conjunto de treino: {train_accuracy:.3f}')
print(f'Acurácia no conjunto de teste: {test_accuracy:.3f}')

"""**Avaliando overfitting**"""

# Avaliando Overfitting

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, roc_curve, confusion_matrix

# Carregar os dados
df = pd.read_csv('/content/score.csv')

# Separar as características (X) e a variável dependente (y)
X = df[['age_dummy', 'dependent_dummy', 'salary_dummy', 'total_loans_dummy', 'more_90_days_dummy', 'using_lines_dummy', 'debt_ratio_dummy']]
y = df['default_flag']

# Dividir os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Estandarizar as características
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar o modelo de regressão logística
model = LogisticRegression(class_weight='balanced')

# Treinar o modelo nos dados de treino
model.fit(X_train, y_train)

# Realizar predições nos conjuntos de treino e teste
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Avaliar o modelo nos dados de treino
train_accuracy = accuracy_score(y_train, y_train_pred)
train_precision = precision_score(y_train, y_train_pred)
train_recall = recall_score(y_train, y_train_pred)
train_f1 = f1_score(y_train, y_train_pred)
train_roc_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])
train_log_loss = log_loss(y_train, model.predict_proba(X_train))

# Avaliar o modelo nos dados de teste
test_accuracy = accuracy_score(y_test, y_test_pred)
test_precision = precision_score(y_test, y_test_pred)
test_recall = recall_score(y_test, y_test_pred)
test_f1 = f1_score(y_test, y_test_pred)
test_roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
test_log_loss = log_loss(y_test, model.predict_proba(X_test))

# Imprimir métricas de avaliação nos conjuntos de treino e teste
print("\033[1mMétricas de Avaliação:\033[0m")
print("\nTreino:")
print(f"Exatidão (Accuracy): {train_accuracy:.3f}")
print(f"Precisão: {train_precision:.3f}")
print(f"Sensibilidade (Recall): {train_recall:.3f}")
print(f"F1-score: {train_f1:.3f}")
print(f"AUC-ROC: {train_roc_auc:.3f}")
print(f"Log-Loss: {train_log_loss:.3f}")

print("\nTeste:")
print(f"Exatidão (Accuracy): {test_accuracy:.3f}")
print(f"Precisão: {test_precision:.3f}")
print(f"Sensibilidade (Recall): {test_recall:.3f}")
print(f"F1-score: {test_f1:.3f}")
print(f"AUC-ROC: {test_roc_auc:.3f}")
print(f"Log-Loss: {test_log_loss:.3f}")

# Avaliar o modelo usando validação cruzada (cross-validation)
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
print(f'\nAcurácia média com validação cruzada (CV=5): {cv_scores.mean():.3f}')

"""*Métricas nos Dados de Treino:*

Exatidão (Accuracy): A proporção de previsões corretas feitas pelo modelo. O modelo acertou cerca de 93% das previsões nos dados de treino.

Precisão: 19.6% das previsões positivas do modelo estão corretas.

Sensibilidade (Recall): o modelo conseguiu identificar corretamente 88.6% dos casos de inadimplência (default_flag = 1).

F1-score: o valor de F1-score é 0.321, indicando um equilíbrio moderado entre precisão e recall.

AUC-ROC: possui um AUC-ROC de 0.952, o que é considerado bom.

Log-Loss: A medida da performance de um classificador onde o valor ideal é 0. Seu modelo tem um Log-Loss de 0.276 nos dados de treino.

*Métricas nos Dados de Teste:*

As métricas nos dados de teste são muito semelhantes às métricas de treino, o que é um bom sinal de que o modelo está generalizando bem para novos dados. Isso sugere que não há um overfitting significativo.

Acurácia Média com Validação Cruzada (CV=5):
A acurácia média obtida através da validação cruzada (CV=5) é de 93.0%. Isso indica que o modelo tem um bom desempenho médio em diferentes divisões dos dados de treino, reforçando a ideia de que ele não está superajustado aos dados específicos do treino.

O modelo possui uma alta acurácia e AUC-ROC tanto nos dados de treino quanto nos dados de teste, o que é positivo.
A precisão é baixa, indicando que o modelo pode estar classificando muitos casos erroneamente como inadimplentes. A sensibilidade é alta, o que significa que o modelo consegue identificar a maioria dos casos de inadimplência.

Conclusão:
Os valores das métricas indicam que o modelo de Regressão Logística está bem ajustado aos dados e não está sofrendo de overfitting significativo.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# Modelo de regressão logística
logistic_model = LogisticRegression()
logistic_model.fit(df[['score']], df['default_flag'])

probabilities = logistic_model.predict_proba(df[['score']])[:, 1]

# Plotando o gráfico de dispersão
plt.figure(figsize=(10, 6))

# Pontos de dados reais
plt.scatter(df['score'], df['default_flag'], alpha=0.5, color='blue', label='Dados reais')

# Adicionando a curva de probabilidade da regressão logística
sorted_indices = np.argsort(df['score'])
sorted_score_dummy = df['score'].iloc[sorted_indices]
sorted_probabilities = probabilities[sorted_indices]
plt.plot(sorted_score_dummy, sorted_probabilities, color='red', label='Probabilidade prevista de Inadimplência')

# Títulos e rótulos
plt.title('Gráfico de dispersão')
plt.xlabel('score')
plt.ylabel('default_flag')
plt.legend()

plt.show()